{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verifying SRD Requirements for DESI LRGs\n",
    "\n",
    "Using the Cascades Internal Data release and updated for the 1% Survey selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from astropy.table import Table, vstack, hstack, unique,join\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "from desitarget.sv3.sv3_targetmask import desi_mask\n",
    "import utils\n",
    "reload(utils)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effective areas for tiles in Cascades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in square degrees\n",
    "#obtained from .dat files `/global/cfs/cdirs/desi/survey/catalogs/SV1/LSS/LSScats/cascades_1`\n",
    "#First row of tiles are from Blanc era the next rows are from cascades\n",
    "areas = {80605:1.3598, 80607:1.13, 80609:1.3628, 80620:1.1664, 80622:1.1108,\n",
    "         80674:1.0142, 80676:1.0222, 80678:0.9804, 80680:1.0768,80708:0.981,\n",
    "         80682:1.1446, 80684:0.9574, 80688:1.145,  80690:1.0748,80670:1.2246,  \n",
    "         80692:0.9072, 80694:0.8778, 80700:1.1644, 80686:1.1666, 80712:0.97,\n",
    "         \n",
    "        }\n",
    "\n",
    "areas = pd.DataFrame(areas.items(), columns=[\"TILEID\", \"AREA\"]).sort_values(by=\"TILEID\")\n",
    "areas = areas.set_index(\"TILEID\", drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file into an astropy table and move it to pandas\n",
    "# pandas is objectively BETTER as can be seen below\n",
    "z_path = Path(\"/global/cfs/cdirs/desi/survey/catalogs/SV1/redshift_comps/cascades/3.1/All/alltiles_Allzinfo_wrz.fits\")\n",
    "z_cat = Table.read(z_path)\n",
    "names = [name for name in z_cat.colnames if len(z_cat[name].shape) <= 1]\n",
    "z_cat = z_cat[names].to_pandas()\n",
    "z_cat = z_cat[(z_cat[\"FIBERSTATUS\"]==0)] #select only good fibers\n",
    "z_cat = z_cat[z_cat[\"TARGETS\"] == b\"QSO+LRG\"] # Use only QSO+LRG Tiles\n",
    "z_cat = z_cat[z_cat[\"TILEID\"].isin(areas[\"TILEID\"].values)] # Use tiles from the above dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ashleys catalog does not have MW extinctions\n",
    "my_path = Path(\"/global/cscratch1/sd/bid13/LRG\")\n",
    "\n",
    "lrg_cat = (Table.read(my_path / (\"LRG_SV3.fits\")).to_pandas()).convert_dtypes(convert_integer=False)\n",
    "z_cat = z_cat.merge(lrg_cat, on=\"TARGETID\", how=\"inner\", validate=\"many_to_one\")\n",
    "\n",
    "z_cat_single = z_cat[(z_cat[\"EFFTIME_DARK\"]>800) & (z_cat[\"EFFTIME_DARK\"]<1200)] # Use data with effective exposure time of about 1000s\n",
    "z_cat_asgn = z_cat[z_cat[\"subset\"]==b\"deep\"]\n",
    "z_cat_deep = z_cat_asgn[z_cat_asgn[\"EFFTIME_DARK\"]>3000] # Deep coadds to get the redshift range\n",
    "# There are duplicates in z_cat_deep since some targets were assigned in two tiles. \n",
    "\n",
    "del lrg_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Densities for each tile\n",
    "The effective areas calculated for the tiles used here are not very trustworthy. So, all the calculations will be done in percentages. This section lists the assignment densities using the effective areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrg_mask = (z_cat_asgn[\"SV3_DESI_TARGET\"].array & desi_mask.mask(\"LRG\"))>0\n",
    "lrg_low_mask = (z_cat_asgn[\"SV3_DESI_TARGET\"] & desi_mask.mask(\"LRG_LOWDENS\"))>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas[\"LRG_count\"] = z_cat_asgn[lrg_mask].groupby(\"TILEID\", sort=True).count()[\"TARGETID\"].values\n",
    "areas[\"LRG_dens\"] = areas[\"LRG_count\"]/areas[\"AREA\"]\n",
    "areas[\"LRG_LOWDENS_count\"] = z_cat_asgn[lrg_low_mask].groupby(\"TILEID\", sort=True).count()[\"TARGETID\"].values\n",
    "areas[\"LRG_LOWDENS_dens\"] = areas[\"LRG_LOWDENS_count\"]/areas[\"AREA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **L2.2.1** The average density of successfully observed, galaxy clustering science-quality LRGs with redshift $0.3 < z < 1.0$ shall be at least $300$ deg $^{-2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fraction of objects in the correct redshift ranges as calculated from the deep coadds\n",
    "\n",
    "**Fraction of bad redshifts in deep = star OR DELTACHI2<15 OR redshift>1.4 / All measurements** \n",
    "\n",
    "**Fraction in correct redshift range = correct redshift range / all good measurements** (definition of good in the above line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrg_mask = (z_cat_deep[\"SV3_DESI_TARGET\"].array & desi_mask.mask(\"LRG\"))>0\n",
    "lrg_low_mask = (z_cat_deep[\"SV3_DESI_TARGET\"] & desi_mask.mask(\"LRG_LOWDENS\"))>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_mask = (z_cat_deep[\"SPECTYPE\"]!=b\"STAR\")\n",
    "deltachi2_mask = (z_cat_deep[\"DELTACHI2\"]>15)\n",
    "z_mask = (z_cat_deep[\"Z\"]<=1.4)\n",
    "\n",
    "z_mask_narrow = (z_cat_deep[\"Z\"]>=0.3) &  (z_cat_deep[\"Z\"]<=1.0)\n",
    "z_mask_wide = (z_cat_deep[\"Z\"]>=0.3) &  (z_cat_deep[\"Z\"]<=1.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_all = z_cat_deep.groupby(by=\"TILEID\", sort=True)\n",
    "\n",
    "grouped_bad = z_cat_deep[ ( (~star_mask) | (~deltachi2_mask) | (~z_mask)) & lrg_mask].groupby(by=\"TILEID\", sort=True)\n",
    "print(f\"Bad redshifts % in LRG (deep): { 100* grouped_bad.count().Z.sum()/grouped_all.count().Z.sum():.3f}\")\n",
    "\n",
    "grouped_bad = z_cat_deep[ ( (~star_mask) | (~deltachi2_mask) | (~z_mask)) & lrg_low_mask].groupby(by=\"TILEID\", sort=True)\n",
    "print(f\"Bad redshifts % in LRG_LOWDENS (deep): {100* grouped_bad.count().Z.sum()/grouped_all.count().Z.sum():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fraction of good objects in redshift range 0.3-1.0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = z_cat_deep[star_mask & deltachi2_mask & z_mask & z_mask_narrow & lrg_mask].groupby(by=\"TILEID\", sort=True)\n",
    "grouped_all = z_cat_deep[star_mask & deltachi2_mask & z_mask & lrg_mask].groupby(by=\"TILEID\", sort=True)\n",
    "print(f\"Correct range among good redshifts % LRG: {100 * grouped.count().Z.sum()/grouped_all.count().Z.sum():.3f}\")\n",
    "\n",
    "grouped = z_cat_deep[star_mask & deltachi2_mask & z_mask & z_mask_narrow & lrg_low_mask].groupby(by=\"TILEID\", sort=True)\n",
    "grouped_all = z_cat_deep[star_mask & deltachi2_mask & z_mask & lrg_low_mask].groupby(by=\"TILEID\", sort=True)\n",
    "print(f\"Correct range among good redshifts % LRG_LOWDENS: {100 * grouped.count().Z.sum()/grouped_all.count().Z.sum():.3f}\")\n",
    "\n",
    "grouped = z_cat_deep[star_mask & deltachi2_mask & z_mask & z_mask_narrow & lrg_mask].groupby(by=\"TILEID\", sort=True)\n",
    "grouped_all = z_cat_deep[lrg_mask].groupby(by=\"TILEID\", sort=True)\n",
    "print(f\"Correct range among all redshifts % LRG: {100 * grouped.count().Z.sum()/grouped_all.count().Z.sum():.3f}\")\n",
    "\n",
    "grouped = z_cat_deep[star_mask & deltachi2_mask & z_mask & z_mask_narrow & lrg_low_mask].groupby(by=\"TILEID\", sort=True)\n",
    "grouped_all = z_cat_deep[lrg_low_mask].groupby(by=\"TILEID\", sort=True)\n",
    "print(f\"Correct range among all redshifts % LRG_LOWDENS: {100 * grouped.count().Z.sum()/grouped_all.count().Z.sum():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fraction of good objects in redshift range 0.3-1.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = z_cat_deep[star_mask & deltachi2_mask & z_mask & z_mask_wide & lrg_mask].groupby(by=\"TILEID\", sort=True)\n",
    "grouped_all = z_cat_deep[star_mask & deltachi2_mask & z_mask & lrg_mask].groupby(by=\"TILEID\", sort=True)\n",
    "print(f\"Correct range among good redshifts % LRG: {100 * grouped.count().Z.sum()/grouped_all.count().Z.sum():.3f}\")\n",
    "\n",
    "grouped = z_cat_deep[star_mask & deltachi2_mask & z_mask & z_mask_wide & lrg_low_mask].groupby(by=\"TILEID\", sort=True)\n",
    "grouped_all = z_cat_deep[star_mask & deltachi2_mask & z_mask & lrg_low_mask].groupby(by=\"TILEID\", sort=True)\n",
    "print(f\"Correct range among good redshifts % LRG_LOWDENS: {100 * grouped.count().Z.sum()/grouped_all.count().Z.sum():.3f}\")\n",
    "\n",
    "grouped = z_cat_deep[star_mask & deltachi2_mask & z_mask & z_mask_wide & lrg_mask].groupby(by=\"TILEID\", sort=True)\n",
    "grouped_all = z_cat_deep[lrg_mask].groupby(by=\"TILEID\", sort=True)\n",
    "print(f\"Correct range among all redshifts % LRG: {100 * grouped.count().Z.sum()/grouped_all.count().Z.sum():.3f}\")\n",
    "\n",
    "grouped = z_cat_deep[star_mask & deltachi2_mask & z_mask & z_mask_wide & lrg_low_mask].groupby(by=\"TILEID\", sort=True)\n",
    "grouped_all = z_cat_deep[lrg_low_mask].groupby(by=\"TILEID\", sort=True)\n",
    "print(f\"Correct range among all redshifts % LRG_LOWDENS: {100 * grouped.count().Z.sum()/grouped_all.count().Z.sum():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fraction of successfull measurements using 1x depth\n",
    "\n",
    "A successful measurement is defined as:\n",
    "- `DELTACHI2` > 15 in deep coadd\n",
    "- `ZWARN` = 0 in every single visit\n",
    "- repeatable in the single visits\n",
    "- z < 1.4 in deep coadd\n",
    "\n",
    "A repeatable measurement is defined as one for which each single exposure measurement satisfies $\\Delta z < 0.0033 (1+z)$ wrt deep coadds. We will only consider measurements for which 1x depth repeat observations are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only exposures for which repeatability analysis is possible\n",
    "z_cat_single[\"mask\"] = np.zeros(len(z_cat_single), dtype=\"bool\")\n",
    "for tile in areas[\"TILEID\"].values:\n",
    "    temp_mask = z_cat_single[z_cat_single[\"TILEID\"]==tile].duplicated(subset=\"TARGETID\", keep=False)\n",
    "    z_cat_single.loc[z_cat_single[\"TILEID\"]==tile, \"mask\"]=temp_mask.values\n",
    "z_cat_single = z_cat_single[z_cat_single[\"mask\"].values]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict deep coadds to the ones having multiple observations\n",
    "# Select only exposures for which repeatability analysis is possible\n",
    "z_cat_deep[\"mask\"] = np.zeros(len(z_cat_deep), dtype=\"bool\")\n",
    "for tile in areas[\"TILEID\"].values:\n",
    "    temp_mask = z_cat_deep[z_cat_deep[\"TILEID\"]==tile][\"TARGETID\"].isin(np.unique(z_cat_single[z_cat_single[\"TILEID\"]==tile][\"TARGETID\"]))\n",
    "    z_cat_deep.loc[z_cat_deep[\"TILEID\"]==tile, \"mask\"]=temp_mask.values\n",
    "z_cat_deep = z_cat_deep[z_cat_deep[\"mask\"].values]   \n",
    "z_cat_single = z_cat_single[z_cat_single[\"TARGETID\"].isin(np.unique(z_cat_deep[\"TARGETID\"]))]\n",
    "\n",
    "# 80694 has 7 and 80678 has 20 usable observations. Maybe remove them in future?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find successful measurements\n",
    "z_cat_deep[\"success\"] = (z_cat_deep[\"DELTACHI2\"]>15).values\n",
    "z_cat_deep[\"success\"] &= (z_cat_deep[\"Z\"]<1.4).values\n",
    "deep_tile_group = z_cat_deep.groupby(\"TILEID\")\n",
    "single_tile_group = z_cat_single.groupby(\"TILEID\")\n",
    "for tile, deep_tile_subset in deep_tile_group:\n",
    "    deep_target_group = deep_tile_subset.groupby(\"TARGETID\")\n",
    "    single_target_group = single_tile_group.get_group(tile).groupby(\"TARGETID\")\n",
    "#     print(\"\")\n",
    "#     print(tile, end=\"\\r\")\n",
    "#     print(\"\")\n",
    "    for target, single_target_subset in single_target_group:\n",
    "        z_warn_mask = np.all(single_target_subset[\"ZWARN\"]==0)\n",
    "        z_true = deep_target_group.get_group(target)[\"Z\"]\n",
    "        z_errors = np.abs(single_target_subset[\"Z\"] -  z_true)/(1 + z_true)\n",
    "        z_repeat_mask = np.all(z_errors<0.0033333)\n",
    "        deep_target_group.get_group(target)[\"success\"] &= (z_warn_mask&z_repeat_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrg_mask = (z_cat_deep[\"SV3_DESI_TARGET\"].array & desi_mask.mask(\"LRG\"))>0\n",
    "lrg_low_mask = (z_cat_deep[\"SV3_DESI_TARGET\"] & desi_mask.mask(\"LRG_LOWDENS\"))>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"% of successfull measurements at 1x depth (relative to all measurements)\")\n",
    "print(f\"LRG: {(100*z_cat_deep.success[lrg_mask]).sum()/lrg_mask.sum():.3f} \")\n",
    "print(f\"LRG_LOWDENS: {100*z_cat_deep.success[lrg_low_mask].sum()/lrg_low_mask.sum():.3f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"% of successfull measurements (relative to all measurements) at 1x depth \\nWithin redshifts 0.3 to 1 and not star\")\n",
    "z_mask = ((z_cat_deep.Z>=0.3)&(z_cat_deep.Z<=1))\n",
    "star_mask = z_cat_deep.SPECTYPE != b\"STAR\"\n",
    "print(f\"LRG: {(100*z_cat_deep.success[lrg_mask&z_mask&star_mask]).sum()/lrg_mask.sum():.3f} \")\n",
    "print(f\"LRG_LOWDENS: {100*z_cat_deep.success[lrg_low_mask&z_mask&star_mask].sum()/lrg_low_mask.sum():.3f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"% of successfull measurements (relative to all measurements) at 1x depth \\nWithin redshifts 0.3 to 1.5 and not star\")\n",
    "z_mask = ((z_cat_deep.Z>=0.3)&(z_cat_deep.Z<=1.5))\n",
    "star_mask = z_cat_deep.SPECTYPE != b\"STAR\"\n",
    "print(f\"LRG: {(100*z_cat_deep.success[lrg_mask&z_mask&star_mask]).sum()/lrg_mask.sum():.3f} \")\n",
    "print(f\"LRG_LOWDENS: {100*z_cat_deep.success[lrg_low_mask&z_mask&star_mask].sum()/lrg_low_mask.sum():.3f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"% Redshift range of 0.3 to 1 and not star at 1x depth relative to successful measurements\")\n",
    "z_mask = ((z_cat_deep.Z>=0.3)&(z_cat_deep.Z<=1))\n",
    "star_mask = z_cat_deep.SPECTYPE != b\"STAR\"\n",
    "print(f\"LRG: {(100*z_cat_deep.success[lrg_mask&z_mask&star_mask]).sum()/z_cat_deep.success[lrg_mask].sum():.3f} \")\n",
    "print(f\"LRG_LOWDENS: {100*z_cat_deep.success[lrg_low_mask&z_mask&star_mask].sum()/z_cat_deep.success[lrg_low_mask].sum():.3f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"% Redshift range of 0.3 to 1.4 and not star at 1x depth relative to successful measurements\")\n",
    "z_mask = ((z_cat_deep.Z>=0.3)&(z_cat_deep.Z<=1.4))\n",
    "star_mask = z_cat_deep.SPECTYPE != b\"STAR\"\n",
    "print(f\"LRG: {(100*z_cat_deep.success[lrg_mask&z_mask&star_mask]).sum()/z_cat_deep.success[lrg_mask].sum():.3f} \")\n",
    "print(f\"LRG_LOWDENS: {100*z_cat_deep.success[lrg_low_mask&z_mask&star_mask].sum()/z_cat_deep.success[lrg_low_mask].sum():.3f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins =10\n",
    "z_bins = np.linspace(0.3,1.4, num_bins+1)\n",
    "z_success = []\n",
    "zfiber_bins = np.linspace(z_cat_deep.zfibermag.min(),z_cat_deep.zfibermag.max(), num_bins+1)\n",
    "zfiber_success = []\n",
    "fig , ax = plt.subplots(1,2, figsize=(15,5))\n",
    "ax = np.ravel(ax)\n",
    "for i in range(num_bins):\n",
    "    temp_df = z_cat_deep[(z_cat_deep.Z>=z_bins[i]) & (z_cat_deep.Z<z_bins[i+1])]\n",
    "    z_success.append(100* temp_df.success.sum()/len(temp_df))\n",
    "    temp_df = z_cat_deep[(z_cat_deep.zfibermag>=zfiber_bins[i]) & (z_cat_deep.zfibermag<zfiber_bins[i+1])]\n",
    "    zfiber_success.append(100* temp_df.success.sum()/len(temp_df))\n",
    "ax[0].set_xlabel(\"Spectroscopic Redshift\", size=20)\n",
    "ax[0].set_ylabel(\"Percentage of Success\", size=20)\n",
    "ax[0].set_ylim(98, 101)\n",
    "utils.better_step(z_bins, z_success, ax[0])\n",
    "ax[1].set_xlabel(\"z-fiber mag\", size=20)\n",
    "ax[1].set_ylabel(\"Percentage of Success\", size=20)\n",
    "ax[1].set_ylim(98, 101)\n",
    "utils.better_step(zfiber_bins, zfiber_success, ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **L2.2.2** The random error on individual LRG redshifts in a ∼Gaussian core shall be less than $\\sigma_{z} = 0.0005(1 + z)$ (equivalent to 150 km/s rms).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we consider each 1x depth measurement with multiple observations. We also restrict to measurements with:\n",
    "- `ZWARN` = 0 \n",
    "- `SPECTYPE`!= \"STAR\"\n",
    "- `Z`<1.4\n",
    "- `DELTACHI2<15`\n",
    "\n",
    "For them we calculate every possible pair of $\\Delta z/(1+z)$ and measure their spread and outlier rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_cat_single = z_cat[(z_cat[\"EFFTIME_DARK\"]>800) & (z_cat[\"EFFTIME_DARK\"]<1200)] # Use data with effective exposure time of about 1000s\n",
    "\n",
    "# Select only exposures for which repeatability analysis is possible\n",
    "z_cat_single[\"mask\"] = np.zeros(len(z_cat_single), dtype=\"bool\")\n",
    "for tile in areas[\"TILEID\"].values:\n",
    "    temp_mask = z_cat_single[z_cat_single[\"TILEID\"]==tile].duplicated(subset=\"TARGETID\", keep=False)\n",
    "    z_cat_single.loc[z_cat_single[\"TILEID\"]==tile, \"mask\"]=temp_mask.values\n",
    "z_cat_single = z_cat_single[z_cat_single[\"mask\"].values]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_cat_single = z_cat_single[z_cat_single[\"ZWARN\"]==0]\n",
    "z_cat_single = z_cat_single[z_cat_single[\"SPECTYPE\"]!=b\"STAR\"]\n",
    "z_cat_single = z_cat_single[z_cat_single[\"DELTACHI2\"]>15]\n",
    "z_cat_single = z_cat_single[z_cat_single[\"Z\"]<1.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrg_mask = (z_cat_single[\"SV3_DESI_TARGET\"].array & desi_mask.mask(\"LRG\"))>0\n",
    "lrg_low_mask = (z_cat_single[\"SV3_DESI_TARGET\"] & desi_mask.mask(\"LRG_LOWDENS\"))>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_errors_lrg=np.array([])\n",
    "z_single_grouped_lrg = (z_cat_single[lrg_mask]).groupby(\"TARGETID\")\n",
    "for target, group in z_single_grouped_lrg:\n",
    "    z = group[\"Z\"].values\n",
    "    zerrors = np.abs(z[None, :] - z[:, None])/(1+z[None, :]) #find all possible errors\n",
    "    zerrors = zerrors[~np.eye(len(z),dtype=\"bool\")] # Select\n",
    "    all_errors_lrg = np.concatenate([all_errors_lrg, zerrors])\n",
    "\n",
    "all_errors_lrg_low=np.array([])\n",
    "z_single_grouped_lrg_low = (z_cat_single[lrg_low_mask]).groupby(\"TARGETID\")\n",
    "for target, group in z_single_grouped_lrg_low:\n",
    "    z = group[\"Z\"].values\n",
    "    zerrors = np.abs(z[None, :] - z[:, None])/(1+z[None, :]) #find all possible errors\n",
    "    zerrors = zerrors[~np.eye(len(z),dtype=\"bool\")]\n",
    "    all_errors_lrg_low = np.concatenate([all_errors_lrg_low, zerrors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"LRG σ_z = {stats.median_abs_deviation(all_errors_lrg,scale='normal')/np.sqrt(2):.5f}(1+z)\")\n",
    "print(f\"LRG_LOWDENS σ_z = {stats.median_abs_deviation(all_errors_lrg_low,scale='normal')/np.sqrt(2):.5f}(1+z)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins =10\n",
    "z_bins = np.linspace(0.3,1.4, num_bins+1)\n",
    "z_error_lrg = []\n",
    "z_error_lrg_low = []\n",
    "zfiber_bins = np.linspace(z_cat_single.zfibermag.min(),z_cat_single.zfibermag.max(), num_bins+1)\n",
    "zfiber_error_lrg = []\n",
    "zfiber_error_lrg_low = []\n",
    "fig , ax = plt.subplots(1,2, figsize=(15,5))\n",
    "ax = np.ravel(ax)\n",
    "for i in range(num_bins):\n",
    "    all_errors_lrg_=np.array([])\n",
    "    # Maybe bin using the deep redshifts?\n",
    "    z_single_grouped_lrg = (z_cat_single[lrg_mask & (z_cat_single.Z>=z_bins[i]) & (z_cat_single.Z<z_bins[i+1])]).groupby(\"TARGETID\")\n",
    "    for target, group in z_single_grouped_lrg:\n",
    "        z = group[\"Z\"].values\n",
    "        zerrors = np.abs(z[None, :] - z[:, None])/(1+z[None, :]) #find all possible errors\n",
    "        zerrors = zerrors[~np.eye(len(z),dtype=\"bool\")] # Select\n",
    "        all_errors_lrg_ = np.concatenate([all_errors_lrg_, zerrors])\n",
    "    z_error_lrg.append(stats.median_abs_deviation(all_errors_lrg_,scale='normal')/np.sqrt(2))\n",
    "    \n",
    "    all_errors_lrg_=np.array([])\n",
    "    # Maybe bin using the deep redshifts?\n",
    "    z_single_grouped_lrg = (z_cat_single[lrg_mask & (z_cat_single.zfibermag>=zfiber_bins[i]) & (z_cat_single.zfibermag<zfiber_bins[i+1])]).groupby(\"TARGETID\")\n",
    "    for target, group in z_single_grouped_lrg:\n",
    "        z = group[\"Z\"].values\n",
    "        zerrors = np.abs(z[None, :] - z[:, None])/(1+z[None, :]) #find all possible errors\n",
    "        zerrors = zerrors[~np.eye(len(z),dtype=\"bool\")] # Select\n",
    "        all_errors_lrg_ = np.concatenate([all_errors_lrg_, zerrors])\n",
    "    zfiber_error_lrg.append(stats.median_abs_deviation(all_errors_lrg_,scale='normal')/np.sqrt(2))\n",
    "    \n",
    "    all_errors_lrg_=np.array([])\n",
    "    z_single_grouped_lrg = (z_cat_single[lrg_low_mask & (z_cat_single.Z>=z_bins[i]) & (z_cat_single.Z<z_bins[i+1])]).groupby(\"TARGETID\")\n",
    "    for target, group in z_single_grouped_lrg:\n",
    "        z = group[\"Z\"].values\n",
    "        zerrors = np.abs(z[None, :] - z[:, None])/(1+z[None, :]) #find all possible errors\n",
    "        zerrors = zerrors[~np.eye(len(z),dtype=\"bool\")] # Select\n",
    "        all_errors_lrg_ = np.concatenate([all_errors_lrg_, zerrors])\n",
    "    z_error_lrg_low.append(stats.median_abs_deviation(all_errors_lrg_,scale='normal')/np.sqrt(2))\n",
    "    \n",
    "    all_errors_lrg_=np.array([])\n",
    "    z_single_grouped_lrg = (z_cat_single[lrg_low_mask & (z_cat_single.zfibermag>=zfiber_bins[i]) & (z_cat_single.zfibermag<zfiber_bins[i+1])]).groupby(\"TARGETID\")\n",
    "    for target, group in z_single_grouped_lrg:\n",
    "        z = group[\"Z\"].values\n",
    "        zerrors = np.abs(z[None, :] - z[:, None])/(1+z[None, :]) #find all possible errors\n",
    "        zerrors = zerrors[~np.eye(len(z),dtype=\"bool\")] # Select\n",
    "        all_errors_lrg_ = np.concatenate([all_errors_lrg_, zerrors])\n",
    "    zfiber_error_lrg_low.append(stats.median_abs_deviation(all_errors_lrg_,scale='normal')/np.sqrt(2))\n",
    "    \n",
    "    \n",
    "ax[0].set_xlabel(\"Spectroscopic Redshift\", size=20)\n",
    "ax[0].set_ylabel(\"$\\sigma_{z}$\", size=20)\n",
    "ax[0].axhline(0.0005, ls=\"--\", c= \"k\", label=\"Requirement\")\n",
    "utils.better_step(z_bins, z_error_lrg, ax[0], label=\"LRG\")\n",
    "utils.better_step(z_bins, z_error_lrg_low, ax[0], label=\"LRG_LOWDENS\", ls=\"--\")\n",
    "# ax[0].set_ylim(0, 0.00052)\n",
    "ax[1].set_xlabel(\"z-fiber mag\", size=20)\n",
    "ax[1].set_ylabel(\"$\\sigma_{z}$\", size=20)\n",
    "ax[1].axhline(0.0005, ls=\"--\", c= \"k\", label=\"Requirement\")\n",
    "# ax[1].set_ylim(0, 0.00052)\n",
    "utils.better_step(zfiber_bins, zfiber_error_lrg, ax[1], label=\"LRG\")\n",
    "utils.better_step(zfiber_bins, zfiber_error_lrg_low, ax[1], label=\"LRG_LOWDENS\", ls=\"--\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **L2.2.3** Systematic inaccuracy in the mean LRG redshift shall be less than $\\Delta z = 0.0002(1+ z)$ (equivalent to 60 km/s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See separate notebook which uses stacking to check this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **L2.2.4** LRG redshift catastrophic failures exceeding 1000 km/s shall be < 5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Catastrophic Outlier %\")\n",
    "frac = (all_errors_lrg>0.00333).sum()*100/len(all_errors_lrg)\n",
    "print(f\"LRG: {frac/2:.3f}-{frac:.3f}%\")\n",
    "frac = (all_errors_lrg_low>0.00333).sum()*100/len(all_errors_lrg_low)\n",
    "print(f\"LRG_LOWDENS: {frac/2:.3f}-{frac:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the above as a function of redshift and zfiber?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **L2.2.5** The LRG redshift completeness shall be >95% for each pointing averaged over all targets that receive fibers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See section 2.2.1 for the fractions of successfull measurements/total measurements. NaN values indicate no elligible objects were found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrg_mask = (z_cat_deep[\"SV3_DESI_TARGET\"].array & desi_mask.mask(\"LRG\"))>0\n",
    "lrg_low_mask = (z_cat_deep[\"SV3_DESI_TARGET\"] & desi_mask.mask(\"LRG_LOWDENS\"))>0\n",
    "\n",
    "group_lrg = (z_cat_deep[lrg_mask]).groupby(\"TILEID\")\n",
    "group_lrg_low = (z_cat_deep[lrg_low_mask]).groupby(\"TILEID\")\n",
    "\n",
    "completeness = pd.DataFrame({ \"LRG\":(100*group_lrg[\"success\"].sum()/group_lrg[\"success\"].count()),\n",
    "                             \"LRG_count\": group_lrg[\"success\"].count(),\n",
    "                             \"LRG_LOWDENS\":(100*group_lrg_low[\"success\"].sum()/group_lrg_low[\"success\"].count()),\n",
    "                             \"LRG_LOWDENS_count\": group_lrg_low[\"success\"].count(),\n",
    "                             \n",
    "}, index=areas[\"TILEID\"])\n",
    "completeness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **L2.8.1** The LRG target density shall be 350 per deg2, with at least 300 per deg2 successfully measured (§L2.2.1). With a fiber assignment efficiency of 99% for LRGs, this implies a combined target selection and redshift measurement efficiency of 87%. The magnitude limit for this sample is z$_{\\mathrm{AB}} < 20.56$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See section 2.2.1 for the fractions of successfull measurements in the given redshift range."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
